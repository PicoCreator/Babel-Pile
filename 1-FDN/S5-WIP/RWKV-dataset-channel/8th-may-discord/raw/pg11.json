{"analytics_id": "ea8dfcc277483ab68575a85d81d28ace", "doing_deep_historical_index": false, "total_results": 291, "messages": [[{"id": "1079186551713570857", "type": 0, "content": "not sure if i should cross post an Issue for that, already made and issue for it in Open Assistant github **https://github.com/LAION-AI/Open-Assistant/issues/1888** let me know if cross-issue would be acceptable", "channel_id": "998539369919025212", "author": {"id": "122392479902203904", "username": "epicx", "global_name": null, "display_name": null, "avatar": "dbb80df69f626a39fae237fe8493d757", "discriminator": "7921", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/LAION-AI/Open-Assistant/issues/1888**", "title": "Issues \u00b7 LAION-AI/Open-Assistant", "description": "OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so. - Issues \u00b7 LAION-AI/Open-Assistant", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/9ae5bb6bbc4a966f764b71e22c916678e9ae2d85fe815e11a968c48cb896522f/LAION-AI/Open-Assistant", "proxy_url": "https://images-ext-2.discordapp.net/external/JCcrYE9o5LhfSkTkTzQKKM_tT6tbuxmDXn8qVevTNUk/https/opengraph.githubassets.com/9ae5bb6bbc4a966f764b71e22c916678e9ae2d85fe815e11a968c48cb896522f/LAION-AI/Open-Assistant", "width": 1200, "height": 600}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-25T23:42:04.245000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1079177685596655656", "type": 0, "content": "Stanford released what could an ideal RLHF starting dataset\n\nhttps://huggingface.co/datasets/stanfordnlp/SHP", "channel_id": "998539369919025212", "author": {"id": "122392479902203904", "username": "epicx", "global_name": null, "display_name": null, "avatar": "dbb80df69f626a39fae237fe8493d757", "discriminator": "7921", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://huggingface.co/datasets/stanfordnlp/SHP", "title": "stanfordnlp/SHP \u00b7 Datasets at Hugging Face", "thumbnail": {"url": "https://thumbnails.huggingface.co/social-thumbnails/datasets/stanfordnlp/SHP.png", "proxy_url": "https://images-ext-1.discordapp.net/external/hkFnH9HVZW4aXC7KBk-gxAnPv-SKJMEisra9GcRebFo/https/thumbnails.huggingface.co/social-thumbnails/datasets/stanfordnlp/SHP.png", "width": 1200, "height": 648}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-25T23:06:50.398000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1078870483488997479", "type": 19, "content": "Research shows over-curation might be detrimental: https://arxiv.org/abs/2208.01009\nIt seems \"good data\" might come from non-obvious sources. So, for base LM pretraining we might want to avoid being too selective (thus, for example, LLAMA includes both CommonCrawl and C4 which differ in their filter criteria).\n\nLater, in the fine-tuning stage, the model can be focused to model \"good data\".", "channel_id": "998539369919025212", "author": {"id": "743939899152924802", "username": "Semantic Aberration", "global_name": null, "display_name": null, "avatar": "c28192826469402f9e36a3bb94751950", "discriminator": "3692", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "link", "url": "https://arxiv.org/abs/2208.01009", "title": "Few-shot Adaptation Works with UnpredicTable Data", "description": "Prior work on language models (LMs) shows that training on a large number of\ndiverse tasks improves few-shot learning (FSL) performance on new tasks. We\ntake this to the extreme, automatically extracting 413,299 tasks from internet\ntables - orders of magnitude more than the next-largest public datasets.\nFinetuning on the resulting dataset leads ...", "reference_id": "1078870483488997479", "provider": {"name": "arXiv.org"}, "thumbnail": {"url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "proxy_url": "https://images-ext-2.discordapp.net/external/LIyASlFffiTdsiX_2bt7vMzsHs9cV_I7u2hOMKXjLyc/https/static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "width": 1200, "height": 700}}], "mentions": [{"id": "370573614791000065", "username": "tiendung", "global_name": null, "display_name": null, "avatar": "3afb621c239c5805ab71b2f9ad3f148e", "discriminator": "4721", "public_flags": 0, "avatar_decoration": null}], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-25T02:46:07.708000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "message_reference": {"channel_id": "998539369919025212", "guild_id": "992359628979568762", "message_id": "1078869505486356540"}, "hit": true}], [{"id": "1078859451056017518", "type": 0, "content": "<@870137517020688415> <@449762604269961226> <@156649559034953728> I made a basic repo for our would be LLAMA replication, with a README summary for now https://github.com/yuxdux/kinda-llama/blob/main/README.md", "channel_id": "998539369919025212", "author": {"id": "743939899152924802", "username": "Semantic Aberration", "global_name": null, "display_name": null, "avatar": "c28192826469402f9e36a3bb94751950", "discriminator": "3692", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/yuxdux/kinda-llama/blob/main/README.md", "title": "kinda-llama/README.md at main \u00b7 yuxdux/kinda-llama", "description": "An open-source replication and modification of the Meta AI's LLAMA dataset - kinda-llama/README.md at main \u00b7 yuxdux/kinda-llama", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/5c061a5c7417ab49699ed3332829fc8a8dadb138b0885f0a8122c3a3d2a377ee/yuxdux/kinda-llama", "proxy_url": "https://images-ext-2.discordapp.net/external/f3ZE5MUncWMu8h0qBetKN4dfGZZj6c1bgGrklRPFURc/https/opengraph.githubassets.com/5c061a5c7417ab49699ed3332829fc8a8dadb138b0885f0a8122c3a3d2a377ee/yuxdux/kinda-llama", "width": 1200, "height": 600}}], "mentions": [{"id": "156649559034953728", "username": "MrSteyk", "global_name": null, "display_name": null, "avatar": "d944352f53cfad33d8b3a9acf9e8105f", "discriminator": "3110", "public_flags": 64, "avatar_decoration": null}, {"id": "449762604269961226", "username": "--=ASTRO=--", "global_name": null, "display_name": null, "avatar": "b9c39e9ef76ba93d15aa6bcf794d6443", "discriminator": "6992", "public_flags": 0, "avatar_decoration": null}, {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-25T02:02:17.371000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1078845786403647518", "type": 19, "content": "Yeah, we can be smart and make it like lego bricks without having to store and transmit 3x data. The Pile-V1 is already sharded https://the-eye.eu/public/AI/pile/train/ , we might just label the shards as belonging to (1) (2) or (3) sets.", "channel_id": "998539369919025212", "author": {"id": "743939899152924802", "username": "Semantic Aberration", "global_name": null, "display_name": null, "avatar": "c28192826469402f9e36a3bb94751950", "discriminator": "3692", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [], "mentions": [{"id": "449762604269961226", "username": "--=ASTRO=--", "global_name": null, "display_name": null, "avatar": "b9c39e9ef76ba93d15aa6bcf794d6443", "discriminator": "6992", "public_flags": 0, "avatar_decoration": null}], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-25T01:07:59.464000+00:00", "edited_timestamp": "2023-02-25T01:08:10.289000+00:00", "flags": 0, "components": [], "message_reference": {"channel_id": "998539369919025212", "guild_id": "992359628979568762", "message_id": "1078844501797388339"}, "hit": true}], [{"id": "1078843733522522193", "type": 0, "content": "(3/3)\n\n7. Stackexchange - freely available from web archive. Pile-V1 has stackexchange data too, but LLAMA likely has a superset of it due to later date. LLAMA's preprocessing is very simple, could be implemented within this codebase from Pile's authors: https://github.com/EleutherAI/stackexchange-dataset\n\nImportant note: **in an attempt to enhance number representation, LLAMA authors split all numbers into individual digits**. We likely would be better off doing this as well, otherwise models hardly learn mathematics. This could be implemented without changing the legacy 20B_tokenizer.json to keep compatibility with available checkpoints.\n\nTechnically, the most complicated parts of the dataset are likely these: ArXiv, Wikipedia, Books. I expect some of the subdatasets to be very large and to have small compute hotspots we might want to rewrite in something other than interpreted python to execute it in time on volunteer hardware.\n\nIn short, there are many pieces available to imitate and surpass LLAMA dataset, but there is no 100% complete workflow and some programming will be required to build it to completion, in addition to compute donation to execute it and produce the dataset.\n\nIf our goal were to surpass the LLAMA dataset, we might think about creating these addons:\n2.1. Add more scientific papers - pubmed and scihub (pubmed was included in Pile-V1 though)\n2.2. Add more science and engineering literature from libgen, OCR-ed if necessary. Some of it doesn't need OCR and could be quickly included with a pipeline similar to 5. (\"Books\")\n2.3. Add DM-math from Pile-V1\n2.4. Add more code from github - code modeling seems to help LMs.\n2.5. Add more dialogue data\n2.6. Add <work></work> tokens with reasoning chains like in galactica (requires source of reasoning)", "channel_id": "998539369919025212", "author": {"id": "743939899152924802", "username": "Semantic Aberration", "global_name": null, "display_name": null, "avatar": "c28192826469402f9e36a3bb94751950", "discriminator": "3692", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/EleutherAI/stackexchange-dataset", "title": "GitHub - EleutherAI/stackexchange-dataset: Python tools for process...", "description": "Python tools for processing the stackexchange data dumps into a text dataset for Language Models - GitHub - EleutherAI/stackexchange-dataset: Python tools for processing the stackexchange data dump...", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/cd034a28360748c18fab34802792c69da4d46249c2e65cae5a6ae7936b63ff8e/EleutherAI/stackexchange-dataset", "proxy_url": "https://images-ext-2.discordapp.net/external/n0sUM3S3CHa78DIpXeD4OUgOuthOT_tqeokHFr73_is/https/opengraph.githubassets.com/cd034a28360748c18fab34802792c69da4d46249c2e65cae5a6ae7936b63ff8e/EleutherAI/stackexchange-dataset", "width": 1200, "height": 600}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-25T00:59:50.019000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1078843660692619346", "type": 0, "content": "(2/3)\n\n4. Wikipedia - they use latest summer 2022 dumps of Wikipedia in many languages(bg, ca, cs, da, de, en, es, fr, hr, hu, it, nl, pl, pt, ro, ru, sl, sr, sv, uk), while Pile-V1 used just an older dump of english wikipedia. They sample Wikipedia two times. Clearly this one is important enough to be shown several times, so I think we don't need deduplication here. The dumps are available at https://dumps.wikimedia.org/backup-index.html and we can process them with one of these https://github.com/shyamupa/wikidump_preprocessing https://github.com/singletongue/wikipedia-utils https://github.com/siznax/wptools (if you know a better tool, comment).\n5. Books - they use a mix of public domain books from Gutenberg project and a copy of Pile-V1 books section, thus we need to take a different set of quality books from libgen and clean+tokenize them with Pile-derived script to avoid duplication. They also implement deduplication at a book level with 90% threshold which wasn't the case with Pile. We will need fast custom code for this (comment if you know a good codebase to start from).\n6. ArXiv - they use ArXiv Latex dump https://info.arxiv.org/help/bulk_data_s3.html with extensive postprocessing (removal of intro pages and bibliography, **latex macro expansion**). It overlaps with Pile-V1 ArXiv subsection, but Pile-V1 lacks papers submitted in the last 3 years and it didn't use special preprocessing. Given success of Galactica LM with its multi-epoch training on scientific literature, we likely would be better served by avoiding deduplication here and just copying what LLAMA did for data processing. At a glance I don't see an exactly equivalent Arxiv script, so we might need to develop our own from one of these: https://github.com/EleutherAI/pile-arxiv https://github.com/mattbierbaum/arxiv-public-datasets https://github.com/amacfie/mathtext", "channel_id": "998539369919025212", "author": {"id": "743939899152924802", "username": "Semantic Aberration", "global_name": null, "display_name": null, "avatar": "c28192826469402f9e36a3bb94751950", "discriminator": "3692", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/shyamupa/wikidump_preprocessing", "title": "GitHub - shyamupa/wikidump_preprocessing: Extracting useful metadat...", "description": "Extracting useful metadata from Wikipedia dumps in any language. - GitHub - shyamupa/wikidump_preprocessing: Extracting useful metadata from Wikipedia dumps in any language.", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/ea57cde26d16e09d8275c674e9954b532a0325bde04fc88078c9e52bfd118c15/shyamupa/wikidump_preprocessing", "proxy_url": "https://images-ext-1.discordapp.net/external/Lkt9NnVRn9XvzV7-krbrkA5pvEG5tj7YQQZPw9HvxOY/https/opengraph.githubassets.com/ea57cde26d16e09d8275c674e9954b532a0325bde04fc88078c9e52bfd118c15/shyamupa/wikidump_preprocessing", "width": 1200, "height": 600}}, {"type": "article", "url": "https://github.com/singletongue/wikipedia-utils", "title": "GitHub - singletongue/wikipedia-utils: Utility scripts for preproce...", "description": "Utility scripts for preprocessing Wikipedia texts for NLP - GitHub - singletongue/wikipedia-utils: Utility scripts for preprocessing Wikipedia texts for NLP", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/dbc7f88533fd3bff42f32ea92fb3d5758d8686cf431a78c756f6dc8342b10acb/singletongue/wikipedia-utils", "proxy_url": "https://images-ext-1.discordapp.net/external/NVRtxy1nT0pDbEJYQaNNjt_mIhepnV6QTavOBtvkmnk/https/opengraph.githubassets.com/dbc7f88533fd3bff42f32ea92fb3d5758d8686cf431a78c756f6dc8342b10acb/singletongue/wikipedia-utils", "width": 1200, "height": 600}}, {"type": "article", "url": "https://github.com/siznax/wptools", "title": "GitHub - siznax/wptools: Wikipedia tools (for Humans): easily extra...", "description": "Wikipedia tools (for Humans): easily extract data from Wikipedia, Wikidata, and other MediaWikis - GitHub - siznax/wptools: Wikipedia tools (for Humans): easily extract data from Wikipedia, Wikidat...", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/6ff1bd21a103fb182eaa39ac1f649f2bbceeb611e09a38170be8705a94a3d7db/siznax/wptools", "proxy_url": "https://images-ext-2.discordapp.net/external/RIxpu0ctxlHvFar31PWip0Uf9C_QLHBVyAjx0wfZoJI/https/opengraph.githubassets.com/6ff1bd21a103fb182eaa39ac1f649f2bbceeb611e09a38170be8705a94a3d7db/siznax/wptools", "width": 1200, "height": 600}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-25T00:59:32.655000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1078843536570589224", "type": 0, "content": "(1/3) <@870137517020688415> <@156649559034953728> <@312617505946337281> <@449762604269961226> \n\nMy overview on LLAMA dataset, keeping in mind three possible goals, namely (1) pure replication of LLAMA, (2) A superset of LLAMA for better scientific performance - they notice in the paper that they might lose to Minerva in the benchmarks due to not enough technical books and papers and (3) A \"LLAMA minus Pile-V1\" which would allow continuing training from the checkpoints we already have.\n\nNotably, (3) would require deduplication against Pile-V1 with some fast string-hashing algorithm (Pile used simple sha256 hash https://github.com/EleutherAI/the-pile/blob/master/processing_scripts/dedupe_train.py but there might be better solutions)\n\nThus, the overview:\n\n1. CommonCrawl is taken from here https://commoncrawl.org/the-data/get-started/ and processed with this https://github.com/facebookresearch/cc_net (likely a decent amount of CPU compute needed, as it is written in python, we could profile and accelerate the hotspots).\n2. C4 is on huggingface https://huggingface.co/datasets/allenai/c4 - we might think about which exact (noclean, clean) version to use.\n3. Github - they used bigquery dump (it requires google account to access), we could use more extensive dumps such as https://huggingface.co/datasets/codeparrot/github-code (free) or https://huggingface.co/datasets/bigcode/the-stack (free, requires a form sign-in). Pile-V1 included 95 GiB Github section, so we need to deduplicate against it.", "channel_id": "998539369919025212", "author": {"id": "743939899152924802", "username": "Semantic Aberration", "global_name": null, "display_name": null, "avatar": "c28192826469402f9e36a3bb94751950", "discriminator": "3692", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/EleutherAI/the-pile/blob/master/processing_scripts/dedupe_train.py", "title": "the-pile/dedupe_train.py at master \u00b7 EleutherAI/the-pile", "description": "Contribute to EleutherAI/the-pile development by creating an account on GitHub.", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/bdbc00121d1f30be6277839815c1c7f5e80acb266cb8fe67fdaacdc4550f55c2/EleutherAI/the-pile", "proxy_url": "https://images-ext-1.discordapp.net/external/yZzus8KZqB5lZ3ncoy1AIMvbsE4GOMa6eYkc1Ab_LgY/https/opengraph.githubassets.com/bdbc00121d1f30be6277839815c1c7f5e80acb266cb8fe67fdaacdc4550f55c2/EleutherAI/the-pile", "width": 1200, "height": 600}}, {"type": "link", "url": "https://commoncrawl.org/the-data/get-started/", "title": "So you\u2019re ready to get started.", "author": {"name": "Barrett Cox", "url": "https://commoncrawl.org/author/barrettcox80/"}, "provider": {"name": "Common Crawl", "url": "https://commoncrawl.org/"}}, {"type": "article", "url": "https://github.com/facebookresearch/cc_net", "title": "GitHub - facebookresearch/cc_net: Tools to download and cleanup Com...", "description": "Tools to download and cleanup Common Crawl data. Contribute to facebookresearch/cc_net development by creating an account on GitHub.", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/399cc615aa7898792a5ca0832916f6ce0b8ae4de1226192b2894e9e5d455a448/facebookresearch/cc_net", "proxy_url": "https://images-ext-2.discordapp.net/external/2YCaTvcvBjbVRA2GehTb-_XX0m_p1maNSCTLv01EM0I/https/opengraph.githubassets.com/399cc615aa7898792a5ca0832916f6ce0b8ae4de1226192b2894e9e5d455a448/facebookresearch/cc_net", "width": 1200, "height": 600}}, {"type": "article", "url": "https://huggingface.co/datasets/allenai/c4", "title": "allenai/c4 \u00b7 Datasets at Hugging Face", "thumbnail": {"url": "https://thumbnails.huggingface.co/social-thumbnails/datasets/allenai/c4.png", "proxy_url": "https://images-ext-1.discordapp.net/external/ZxU0u3tyV0_v0tpk67l9Wi0hE-oX6ogPrM2kJbD16sg/https/thumbnails.huggingface.co/social-thumbnails/datasets/allenai/c4.png", "width": 1200, "height": 648}}, {"type": "article", "url": "https://huggingface.co/datasets/codeparrot/github-code", "title": "codeparrot/github-code \u00b7 Datasets at Hugging Face", "thumbnail": {"url": "https://thumbnails.huggingface.co/social-thumbnails/datasets/codeparrot/github-code.png", "proxy_url": "https://images-ext-2.discordapp.net/external/ALyX57PA1Glj1ewtzOlM3GUoKy7sRYnwFhMUmTPC9fw/https/thumbnails.huggingface.co/social-thumbnails/datasets/codeparrot/github-code.png", "width": 1200, "height": 648}}], "mentions": [{"id": "156649559034953728", "username": "MrSteyk", "global_name": null, "display_name": null, "avatar": "d944352f53cfad33d8b3a9acf9e8105f", "discriminator": "3110", "public_flags": 64, "avatar_decoration": null}, {"id": "312617505946337281", "username": "R4_Unit", "global_name": null, "display_name": null, "avatar": "33f1a4246e20cb01b24e41a6130b35a8", "discriminator": "6424", "public_flags": 0, "avatar_decoration": null}, {"id": "449762604269961226", "username": "--=ASTRO=--", "global_name": null, "display_name": null, "avatar": "b9c39e9ef76ba93d15aa6bcf794d6443", "discriminator": "6992", "public_flags": 0, "avatar_decoration": null}, {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-25T00:59:03.062000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1078828251713122355", "type": 0, "content": "Also here's Blink's post from the start of this channel\n\nhttps://discord.com/channels/992359628979568762/998539369919025212/998596986213236806", "channel_id": "998539369919025212", "author": {"id": "224712880895950848", "username": "Shmingmaster", "global_name": null, "display_name": null, "avatar": "ffbdc8cce216770e37bf9b346927868f", "discriminator": "3961", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-24T23:58:18.868000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1078813078839365742", "type": 0, "content": "Here is my post about it https://discord.com/channels/992359628979568762/992359629419991142/1078049703423381565 ask more questions", "channel_id": "998539369919025212", "author": {"id": "743939899152924802", "username": "Semantic Aberration", "global_name": null, "display_name": null, "avatar": "c28192826469402f9e36a3bb94751950", "discriminator": "3692", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-24T22:58:01.373000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1078389924992126996", "type": 0, "content": "https://huggingface.co/datasets/allenai/soda", "channel_id": "998539369919025212", "author": {"id": "344293257271967744", "username": "amazingvince", "global_name": null, "display_name": null, "avatar": "a2f96da61c887e9b890be7183cc825d1", "discriminator": "5555", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://huggingface.co/datasets/allenai/soda", "title": "allenai/soda \u00b7 Datasets at Hugging Face", "thumbnail": {"url": "https://thumbnails.huggingface.co/social-thumbnails/datasets/allenai/soda.png", "proxy_url": "https://images-ext-2.discordapp.net/external/84fUOaAbrcfv8FS6ZT6e49Y9Wbq46DCjTGIOyIY9PlI/https/thumbnails.huggingface.co/social-thumbnails/datasets/allenai/soda.png", "width": 1200, "height": 648}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-23T18:56:33.634000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1076292671464812596", "type": 0, "content": "https://huggingface.co/datasets/SirNeural/flan_v2 <@870137517020688415>  sorry for the delay lol things took longer to export than i expected", "channel_id": "998539369919025212", "author": {"id": "160498635262394368", "username": "neural", "global_name": null, "display_name": null, "avatar": "2c95c3526bd85b8dc83ff7b9777c2e66", "discriminator": "1337", "public_flags": 256, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://huggingface.co/datasets/SirNeural/flan_v2", "title": "SirNeural/flan_v2 \u00b7 Datasets at Hugging Face", "thumbnail": {"url": "https://thumbnails.huggingface.co/social-thumbnails/datasets/SirNeural/flan_v2.png", "proxy_url": "https://images-ext-1.discordapp.net/external/cxxZXE3ZeeDkOmmVIGHlOfInsw5AfKNMVf53olCZ2Sw/https/thumbnails.huggingface.co/social-thumbnails/datasets/SirNeural/flan_v2.png", "width": 1200, "height": 648}}], "mentions": [{"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-18T00:02:49.428000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1075278464682295406", "type": 0, "content": "https://github.com/asigalov61/Tegridy-MIDI-Dataset", "channel_id": "998539369919025212", "author": {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/asigalov61/Tegridy-MIDI-Dataset", "title": "GitHub - asigalov61/Tegridy-MIDI-Dataset: Tegridy MIDI Dataset for ...", "description": "Tegridy MIDI Dataset for precise and effective Music AI models creation. - GitHub - asigalov61/Tegridy-MIDI-Dataset: Tegridy MIDI Dataset for precise and effective Music AI models creation.", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://repository-images.githubusercontent.com/298652021/0df98c00-8fdb-11eb-8a7d-a9fec38914aa", "proxy_url": "https://images-ext-2.discordapp.net/external/nFjwhL4_x9iM9Rmo86hbkWbDp6CmzlCOBxT-ggtQiiY/https/repository-images.githubusercontent.com/298652021/0df98c00-8fdb-11eb-8a7d-a9fec38914aa", "width": 512, "height": 288}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-15T04:52:43.688000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1074755776800886794", "type": 0, "content": "https://huggingface.co/datasets/irc_disentangle", "channel_id": "998539369919025212", "author": {"id": "745683102910906510", "username": "zukaboo", "global_name": null, "display_name": null, "avatar": null, "discriminator": "8804", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://huggingface.co/datasets/irc_disentangle", "title": "irc_disentangle \u00b7 Datasets at Hugging Face", "thumbnail": {"url": "https://thumbnails.huggingface.co/social-thumbnails/datasets/irc_disentangle.png", "proxy_url": "https://images-ext-2.discordapp.net/external/ccOBjRpOsQZi_GNv7ae8ZPh2wxmHTGERBgveQ4up5wQ/https/thumbnails.huggingface.co/social-thumbnails/datasets/irc_disentangle.png", "width": 1200, "height": 648}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-13T18:15:45.186000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1073098632305328159", "type": 0, "content": "https://github.com/p-lambda/dsir Pre-filtered datasets and code for selecting relevant language model training data from The Pile.", "channel_id": "998539369919025212", "author": {"id": "370573614791000065", "username": "tiendung", "global_name": null, "display_name": null, "avatar": "3afb621c239c5805ab71b2f9ad3f148e", "discriminator": "4721", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-09T04:30:51.150000+00:00", "edited_timestamp": null, "flags": 4, "components": [], "hit": true}], [{"id": "1072688901610811473", "type": 0, "content": "https://github.com/Muennighoff/FLAN/blob/main/prepare_datasets.py", "channel_id": "998539369919025212", "author": {"id": "540962107311652899", "username": "ogkalu", "global_name": null, "display_name": null, "avatar": null, "discriminator": "7841", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/Muennighoff/FLAN/blob/main/prepare_datasets.py", "title": "FLAN/prepare_datasets.py at main \u00b7 Muennighoff/FLAN", "description": "Provides a minimal implementation to extract FLAN datasets for further processing - FLAN/prepare_datasets.py at main \u00b7 Muennighoff/FLAN", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/9935fc26af3406b5769182ff6795dec1962187e1455a7efc301d183d415d161c/Muennighoff/FLAN", "proxy_url": "https://images-ext-2.discordapp.net/external/V8JUavBqSjpW3yqOqqsCeF5Dko2W2nPW7kE6CSQIR0c/https/opengraph.githubassets.com/9935fc26af3406b5769182ff6795dec1962187e1455a7efc301d183d415d161c/Muennighoff/FLAN", "width": 1200, "height": 600}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-08T01:22:43.740000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1072685700874514463", "type": 0, "content": "https://huggingface.co/datasets/Muennighoff/flan", "channel_id": "998539369919025212", "author": {"id": "540962107311652899", "username": "ogkalu", "global_name": null, "display_name": null, "avatar": null, "discriminator": "7841", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://huggingface.co/datasets/Muennighoff/flan", "title": "Muennighoff/flan \u00b7 Datasets at Hugging Face", "thumbnail": {"url": "https://thumbnails.huggingface.co/social-thumbnails/datasets/Muennighoff/flan.png", "proxy_url": "https://images-ext-2.discordapp.net/external/tjvm26XcJiCrPZjwKHQjHnq6BZF4wnci916z4OofhFQ/https/thumbnails.huggingface.co/social-thumbnails/datasets/Muennighoff/flan.png", "width": 1200, "height": 648}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-08T01:10:00.625000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1072508095227514963", "type": 0, "content": "does anyone know how to generate flan v2 training data https://github.com/google-research/FLAN/tree/main/flan/v2", "channel_id": "998539369919025212", "author": {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/google-research/FLAN/tree/main/flan/v2", "title": "FLAN/flan/v2 at main \u00b7 google-research/FLAN", "description": "Contribute to google-research/FLAN development by creating an account on GitHub.", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/00c6f089788142675d5fef9f5cbc762b1f5c7077392ca8b0fa0a57952dd1fcea/google-research/FLAN", "proxy_url": "https://images-ext-2.discordapp.net/external/42WRbRfaIdDPAIH1MbrN3XvPSz3DfyFq_wOXKB05CUQ/https/opengraph.githubassets.com/00c6f089788142675d5fef9f5cbc762b1f5c7077392ca8b0fa0a57952dd1fcea/google-research/FLAN", "width": 1200, "height": 600}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-07T13:24:16.139000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1070393841376579594", "type": 0, "content": "new instruction tuning dataset from google just dropped https://twitter.com/ShayneRedford/status/1620805305801261058 (nm this is 3 weeks old: <https://github.com/google-research/FLAN/tree/main/flan/v2>)", "channel_id": "998539369919025212", "author": {"id": "352889277027319809", "username": "a1k0n", "global_name": null, "display_name": null, "avatar": "84cf8e2c3b5bea6aedbad4eaea82612c", "discriminator": "3903", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-01T17:22:58.740000+00:00", "edited_timestamp": "2023-02-01T17:28:55.341000+00:00", "flags": 4, "components": [], "hit": true}], [{"id": "1070363950417444894", "type": 0, "content": "https://github.com/BlinkDL/RWKV-LM/tree/main/RWKV-v4neo this is already optimized", "channel_id": "998539369919025212", "author": {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/BlinkDL/RWKV-LM/tree/main/RWKV-v4neo", "title": "RWKV-LM/RWKV-v4neo at main \u00b7 BlinkDL/RWKV-LM", "description": "RWKV is a RNN with transformer-level LLM performance. It can be directly trained like a GPT (parallelizable). So it&#39;s combining the best of RNN and transformer - great performance, fast inf...", "color": 1975079, "provider": {"name": "GitHub"}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-01T15:24:12.180000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1070209916607922176", "type": 19, "content": "https://discord.com/channels/992359628979568762/992359845963497512/1067803805128851466", "channel_id": "998539369919025212", "author": {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [], "mentions": [{"id": "451426335043354634", "username": "shaycormac", "global_name": null, "display_name": null, "avatar": "e7c6a379e3968621bf349a074f65fce1", "discriminator": "3079", "public_flags": 0, "avatar_decoration": null}], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-02-01T05:12:07.658000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "message_reference": {"channel_id": "998539369919025212", "guild_id": "992359628979568762", "message_id": "1070209345213698070"}, "hit": true}], [{"id": "1069600767561961532", "type": 0, "content": "https://huggingface.co/spaces/CarperAI/pile-v2-eda", "channel_id": "998539369919025212", "author": {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://huggingface.co/spaces/CarperAI/pile-v2-eda", "title": "Pile V2 EDA - a Hugging Face Space by CarperAI", "thumbnail": {"url": "https://thumbnails.huggingface.co/social-thumbnails/spaces/CarperAI/pile-v2-eda.png", "proxy_url": "https://images-ext-2.discordapp.net/external/GPXBzfMtJ9WwPoqua4YkaJzBT5AhOZsf5AfAZqCNZNY/https/thumbnails.huggingface.co/social-thumbnails/spaces/CarperAI/pile-v2-eda.png", "width": 1200, "height": 648}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-01-30T12:51:35.208000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1069599328395595848", "type": 0, "content": "https://github.com/huggingface/olm-datasets", "channel_id": "998539369919025212", "author": {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://github.com/huggingface/olm-datasets", "title": "GitHub - huggingface/olm-datasets: Pipeline for pulling and process...", "description": "Pipeline for pulling and processing online language model pretraining data from the web - GitHub - huggingface/olm-datasets: Pipeline for pulling and processing online language model pretraining da...", "color": 1975079, "provider": {"name": "GitHub"}, "thumbnail": {"url": "https://opengraph.githubassets.com/183c5fcc4f42c5283809a4dfe1c62e63167b86f230e5054e9e69a37c7a1b6dc9/huggingface/olm-datasets", "proxy_url": "https://images-ext-1.discordapp.net/external/I2DdsSc2iV0lHzcdgeuru9KSz3JiGyOhZTGpTHn3bPI/https/opengraph.githubassets.com/183c5fcc4f42c5283809a4dfe1c62e63167b86f230e5054e9e69a37c7a1b6dc9/huggingface/olm-datasets", "width": 1200, "height": 600}}], "mentions": [], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-01-30T12:45:52.084000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "hit": true}], [{"id": "1066151818951925860", "type": 19, "content": "https://huggingface.co/datasets/bigscience/xP3all/viewer/en/train", "channel_id": "998539369919025212", "author": {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://huggingface.co/datasets/bigscience/xP3all/viewer/en/train", "title": "bigscience/xP3all \u00b7 Datasets at Hugging Face", "reference_id": "1066151818951925860", "thumbnail": {"url": "https://huggingface.co/front/thumbnails/datasets-viewer.png", "proxy_url": "https://images-ext-1.discordapp.net/external/1WRVBv5UBtmP--MPhhmTznwQP9ufIw9IPWaHWOaeWes/https/huggingface.co/front/thumbnails/datasets-viewer.png", "width": 2024, "height": 1012}}], "mentions": [{"id": "376110227600179202", "username": "Zardos", "global_name": null, "display_name": null, "avatar": "f7ae13909b0550dda8c08654e55fb0fd", "discriminator": "6089", "public_flags": 0, "avatar_decoration": null}], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-01-21T00:26:41.781000+00:00", "edited_timestamp": null, "flags": 0, "components": [], "message_reference": {"channel_id": "998539369919025212", "guild_id": "992359628979568762", "message_id": "1066151761305415760"}, "hit": true}], [{"id": "1066144686701551616", "type": 19, "content": "Cool. I am training on https://huggingface.co/datasets/bigscience/xP3all/viewer/en/train first", "channel_id": "998539369919025212", "author": {"id": "870137517020688415", "username": "BlinkDL", "global_name": null, "display_name": null, "avatar": "e465d5d39c9fe14f36982a03dcdb4f4d", "discriminator": "1985", "public_flags": 0, "avatar_decoration": null}, "attachments": [], "embeds": [{"type": "article", "url": "https://huggingface.co/datasets/bigscience/xP3all/viewer/en/train", "title": "bigscience/xP3all \u00b7 Datasets at Hugging Face", "reference_id": "1066144686701551616", "thumbnail": {"url": "https://huggingface.co/front/thumbnails/datasets-viewer.png", "proxy_url": "https://images-ext-1.discordapp.net/external/1WRVBv5UBtmP--MPhhmTznwQP9ufIw9IPWaHWOaeWes/https/huggingface.co/front/thumbnails/datasets-viewer.png", "width": 2024, "height": 1012}}], "mentions": [{"id": "160498635262394368", "username": "neural", "global_name": null, "display_name": null, "avatar": "2c95c3526bd85b8dc83ff7b9777c2e66", "discriminator": "1337", "public_flags": 256, "avatar_decoration": null}], "mention_roles": [], "pinned": false, "mention_everyone": false, "tts": false, "timestamp": "2023-01-20T23:58:21.320000+00:00", "edited_timestamp": "2023-01-21T00:04:05.701000+00:00", "flags": 0, "components": [], "message_reference": {"channel_id": "998539369919025212", "guild_id": "992359628979568762", "message_id": "1066143790865334332"}, "hit": true}]]}